{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Check cuda visible devices\n",
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "print(torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "063b009b32ae4e0e8f25730f46035efc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/2.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8b3cede3de84f87b6c2b2b5c3210890",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/27.4G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jmperez/miniconda3/envs/rioplatense_hs/lib/python3.10/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ\"\n",
        "revision = \"gptq-4bit-32g-actorder_True\" #\"gptq-3bit-128g-actorder_True\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
        "\n",
        "#quantization_config = BitsAndBytesConfig(\n",
        "#    load_in_4bit=True,\n",
        "#    #bnb_4bit_compute_dtype=torch.float16,\n",
        "#    #llm_int8_enable_fp32_cpu_offload=True,\n",
        "#)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    #quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        "    revision=revision,\n",
        "    #llm_int8_enable_fp32_cpu_offload=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Vos podés hacerlo, che!\n",
              "\n",
              "(Nota: \"che\" es una interjección muy común en el español rioplatense, similar a \"eh\" o \"hey\" en inglés, y se utiliza frecuentemente en el habla coloquial)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, clear_output, HTML\n",
        "import textwrap\n",
        "\n",
        "prompt = \"\"\"<s>[INST] Traducir del español al español rioplatense.\n",
        "\n",
        "español: Hola hombre, ¿cómo estás?\n",
        "[/INST]\n",
        "¿Qué onda, chabón? ¿Cómo va?\n",
        "</s>\n",
        "[INST]\n",
        "Traducir del español al rioplatense\n",
        "\n",
        "español: Vaya tío, eres un cabrón\n",
        "[/INST]\n",
        "Che pedazo de pelotudo, sos un forro\n",
        "</s>\n",
        "[INST]\n",
        "Traducir del español al rioplatense\n",
        "\n",
        "español: Tu puedes hacerlo!\n",
        "[/INST]\n",
        "\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "next_token = None\n",
        "new_tokens = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    while next_token != tokenizer.eos_token_id:\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "        output = model.generate(**inputs, max_new_tokens=1, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        next_token = output[0][-1].item()\n",
        "        inputs = {\n",
        "            \"input_ids\": output,\n",
        "            \"attention_mask\": torch.ones_like(output),\n",
        "        }\n",
        "        new_tokens.append(next_token)\n",
        "        text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "        #text = \"\\n\".join(textwrap.wrap(text, width=100))\n",
        "        clear_output(wait=True)\n",
        "        display(HTML(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8DO2gKld8GPv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'text', 'context_tweet', 'HATEFUL', 'body', 'CALLS', 'WOMEN', 'LGBTI', 'RACISM', 'CLASS', 'POLITICS', 'DISABLED', 'APPEARANCE', 'CRIMINAL', 'num_hatred', 'text_label', 'prompt', 'pred_cot'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "sample_path = \"../data/sample_100.csv\"\n",
        "\n",
        "test_ds = load_dataset(\"csv\", data_files=sample_path)[\"train\"]\n",
        "\n",
        "test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wAoJCPrhA833"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "786f6155369140079ab302b9b87f83a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aae9ab7e700049bca58981f2d1dd5985",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pysentimiento.preprocessing import preprocess_tweet as pysent_preprocess\n",
        "from rioplatense_hs.preprocessing import preprocess_tweet, text_to_label, labels\n",
        "from rioplatense_hs.mixtral import get_prompt\n",
        "\n",
        "tokenizer.model_max_length = 8192\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "#\n",
        "def tokenize(example):\n",
        "    texto = preprocess_tweet(example[\"text\"])\n",
        "\n",
        "    contexto = pysent_preprocess(\n",
        "        example[\"context_tweet\"],\n",
        "        preprocess_hashtags=False,\n",
        "        demoji=False,\n",
        "        preprocess_handles=False,\n",
        "    )\n",
        "    model_input = get_prompt(\n",
        "        context=contexto, text=texto\n",
        "    )\n",
        "    return tokenizer(model_input, truncation=True)\n",
        "\n",
        "\n",
        "tokenized_ds = test_ds.map(tokenize, batched=False)\n",
        "# prompt: Sort tokenized_ds by length of input_ids\n",
        "tokenized_ds = tokenized_ds.map(lambda x: {\"len\": len(x[\"input_ids\"])}, batched=False)\n",
        "\n",
        "sorted_tokenized_ds = tokenized_ds.sort(\"len\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[INST] Determinar si el siguiente mensaje contiene discurso de odio.\n",
            "Entendemos que hay discurso de odio en el tweet si tiene declaraciones de carácter intenso e irracional de rechazo, enemistad y aborrecimiento contra un individuo o contra un grupo, siendo objetivos de estas expresiones por poseer una característica protegida. Las características protegidas que contemplamos son:\n",
            "\n",
            "- mujer: mujeres o movimiento feminista\n",
            "- lgbti: contra gays, lesbianas, transexuales y otras identidades de género\n",
            "- racismo: inmigrantes, xenofobia, o contra pueblos aborígenes\n",
            "- clase: personas de bajos recursos o motivos de clase\n",
            "- discapacidad: discapacidad, problemas de salud mental o de adicción al alcohol u otras drogas\n",
            "- política: ideología política\n",
            "- aspecto: aspecto, gordofobia o edad\n",
            "- criminal: presos o delincuentes comunes\n",
            "\n",
            "Responder una o varias de las características separadas por coma, o bien \"nada\" si no hay discurso de odio. Pensar paso a paso la respuesta antes de responder. Finalizar la explicación con \"La respuesta final es\" seguido de la o las características que se hayan identificado.\n",
            "contexto: Al borde del llanto, Nati Jota pidió disculpas por sus repudiables tuits pero los justificó: \"Quería sumar seguidores\"\n",
            "texto: Show o nada mi amorrr!! Sos una imbesil!\n",
            "[/INST]\n",
            "\n",
            "Es un insulto y no menciona nada relacionado a las características protegidas. La respuesta final es \"nada\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Violento motín en la cárcel de Devoto: tomaron e incendiaron pabellones\n",
            "texto: Hermanito lo que son esos grones. Ahí adentro le robaron la billetera al coronavirus\n",
            "[/INST]\n",
            "\n",
            "La palabra \"grones\" significa negros, lo cual alude a su color de piel y aspecto. Además, se refiere a su condición de presos. La respuesta final es \"criminal, racismo, aspecto\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Mayra Mendoza criticó el banderazo contra el Gobierno: \"No tiene sentido y es antidemocrático\"\n",
            "texto: Que negrita villera....ni con la plata q roba puede arreglarse\n",
            "[/INST]\n",
            "\n",
            "El texto alude a su color de piel, a su condición social (villera), y a su aspecto. La respuesta final es \"racismo, aspecto, clase\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Les darán DNI provisorio a personas en situación vulnerable, para que puedan empezar a cobrar planes sociales\n",
            "texto: Seguimos alimentando vagos\n",
            "[/INST]\n",
            "\n",
            "El comentario se refiere a quienes cobran planes sociales como vagos. La respuesta final es \"clase\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Viola Davis, Halle Berry y Angela Bassett, actrices negras que superaron la discriminación en Hollywood\n",
            "texto: el titulo de por si da pena, la nación cree que el racismo es una enfermedad que los que la sufren tienen que superar, es un título discriminatorio\n",
            "[/INST]\n",
            "\n",
            "El comentario critica el título del artículo por insinuar que el racismo es una enfermedad. No critica en ningún momento a las actrices. La respuesta final es \"nada\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: No da tregua: sin ropa y desafiante Flor Peña volvió a mostrar su lado más hot\n",
            "texto: K lado hot tiene más varices k mi abuela. Tiene mas puesta de espalda k karagian trola\n",
            "[/INST]\n",
            "\n",
            "El texto alude a su aspecto (las varices) y la desprecia por \"trola\". La respuesta final es \"mujer, aspecto\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Ginés González García: \"Le tengo mucho miedo al verano, el riesgo va a seguir\"\n",
            "texto: A este viejo le quedan 2 neuronas 1 para comer 2 para cagar\n",
            "[/INST]\n",
            "\n",
            "El texto alude a su edad, aduciendo que no tiene capacidades mentales acordes. La respuesta final es \"aspecto\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Otro ataque de furia contra un colectivero: una mujer trans le pateó la unidad y le tiró un ladrillazo\n",
            "texto: Un tipo operado. Con la fuerza de un hombre y no la de una mujer\n",
            "[/INST]\n",
            "\n",
            "El texto alude a que la mujer trans es un hombre. La respuesta final es \"lgbti\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Elisa Carrió denunció que el Gobierno usa la pandemia para \"establecer un estado de sitio\"\n",
            "texto: Gorda psiquiátrica\n",
            "[/INST]\n",
            "\n",
            "El texto alude a su aspecto (gorda) y la acusa de tener problemas psiquiátricos. La respuesta final es \"aspecto, discapacidad\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: 'País de maricas': ¿Por qué Jair Bolsonaro vuelve a atacar a los homosexuales en Brasil?\n",
            "texto: El discurso de bolsonaro donde dice \"maricas\" es brillante, sólo eso basta para meresca ser el presidente de Sudamérica. Clarín es una cueva de zurdos y progresistas que se pintan los labios punto. Clarín suavecito, te pasas de marica!\n",
            "[/INST]\n",
            "\n",
            "El texto alude a la homosexualidad como algo negativo, a la vez que acusa de ser \"zurdos y progresistas\" a quienes no están de acuerdo con el discurso de Bolsonaro. La respuesta final es \"lgbti, política\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Coronavirus: las terribles imágenes del mercado donde se originó la pandemia\n",
            "texto: Como se llama la obra? Estigmaticemos a los chinos\n",
            "[/INST]\n",
            "\n",
            "El texto critica el titular del artículo por \"estigmatizar a los chinos\". Es un comentario irónico. La respuesta final es \"nada\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: Los dos presos heridos de bala en el motín de Devoto tienen Covid-19 y uno quedó hemipléjico\n",
            "texto: justicia divina!\n",
            "[/INST]\n",
            "\n",
            "El texto alude a que los presos merecen ser baleados. La respuesta final es \"criminal\".\n",
            " \n",
            "\n",
            "[INST] \n",
            "contexto: ¿Se puede ser feminista y llorar a Diego Maradona? url url\n",
            "texto: Ustedes son una mierda\n",
            "[/INST]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# decode first example\n",
        "\n",
        "inputs = sorted_tokenized_ds[0][\"input_ids\"]\n",
        "\n",
        "text = tokenizer.decode(inputs, skip_special_tokens=True)\n",
        "\n",
        "text = text.replace(\"[INST]\", \"\\n[INST]\")\n",
        "text = text.replace(\"[/INST]\", \"[/INST]\\n\")\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VQL9Hs4-YeRv"
      },
      "outputs": [],
      "source": [
        "# prompt: Build a dataloader with a Causal LLM collator\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "batch_size = 16\n",
        "collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "def collate(inputs):\n",
        "    attention = [ex[\"attention_mask\"] for ex in inputs]\n",
        "    input_ids = [ex[\"input_ids\"] for ex in inputs]\n",
        "    ids = [ex[\"id\"] for ex in inputs]\n",
        "    return ids, tokenizer.pad({\"input_ids\": input_ids, \"attention_mask\": attention}, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    sorted_tokenized_ds,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=16,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from auto_gptq import exllama_set_max_input_length\n",
        "model = exllama_set_max_input_length(model, max_input_length=28768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "ids, inputs = next(iter(dataloader))\n",
        "\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "outs = model.generate(**inputs, max_new_tokens=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "</s></s></s></s></s></s></s></s></s></s></s></s></s><s> [INST] Determinar si el siguiente mensaje contiene discurso de odio.\n",
            "Entendemos que hay discurso de odio en el tweet si tiene declaraciones de carácter intenso e irracional de rechazo, enemistad y aborrecimiento contra un individuo o contra un grupo, siendo objetivos de estas expresiones por poseer una característica protegida. Las características protegidas que contemplamos son:\n",
            "\n",
            "- mujer: mujeres o movimiento feminista\n",
            "- lgbti: contra gays, lesbianas, transexuales y otras identidades de género\n",
            "- racismo: inmigrantes, xenofobia, o contra pueblos aborígenes\n",
            "- clase: personas de bajos recursos o motivos de clase\n",
            "- discapacidad: discapacidad, problemas de salud mental o de adicción al alcohol u otras drogas\n",
            "- política: ideología política\n",
            "- aspecto: aspecto, gordofobia o edad\n",
            "- criminal: presos o delincuentes comunes\n",
            "\n",
            "Responder una o varias de las características separadas por coma, o bien \"nada\" si no hay discurso de odio. Pensar paso a paso la respuesta antes de responder. Finalizar la explicación con \"La respuesta final es\" seguido de la o las características que se hayan identificado.\n",
            "contexto: Al borde del llanto, Nati Jota pidió disculpas por sus repudiables tuits pero los justificó: \"Quería sumar seguidores\"\n",
            "texto: Show o nada mi amorrr!! Sos una imbesil!\n",
            "[/INST]\n",
            "Es un insulto y no menciona nada relacionado a las características protegidas. La respuesta final es \"nada\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Violento motín en la cárcel de Devoto: tomaron e incendiaron pabellones\n",
            "texto: Hermanito lo que son esos grones. Ahí adentro le robaron la billetera al coronavirus\n",
            "[/INST]\n",
            "La palabra \"grones\" significa negros, lo cual alude a su color de piel y aspecto. Además, se refiere a su condición de presos. La respuesta final es \"criminal, racismo, aspecto\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Mayra Mendoza criticó el banderazo contra el Gobierno: \"No tiene sentido y es antidemocrático\"\n",
            "texto: Que negrita villera....ni con la plata q roba puede arreglarse\n",
            "[/INST]\n",
            "El texto alude a su color de piel, a su condición social (villera), y a su aspecto. La respuesta final es \"racismo, aspecto, clase\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Les darán DNI provisorio a personas en situación vulnerable, para que puedan empezar a cobrar planes sociales\n",
            "texto: Seguimos alimentando vagos\n",
            "[/INST]\n",
            "El comentario se refiere a quienes cobran planes sociales como vagos. La respuesta final es \"clase\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Viola Davis, Halle Berry y Angela Bassett, actrices negras que superaron la discriminación en Hollywood\n",
            "texto: el titulo de por si da pena, la nación cree que el racismo es una enfermedad que los que la sufren tienen que superar, es un título discriminatorio\n",
            "[/INST]\n",
            "El comentario critica el título del artículo por insinuar que el racismo es una enfermedad. No critica en ningún momento a las actrices. La respuesta final es \"nada\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: No da tregua: sin ropa y desafiante Flor Peña volvió a mostrar su lado más hot\n",
            "texto: K lado hot tiene más varices k mi abuela. Tiene mas puesta de espalda k karagian trola\n",
            "[/INST]\n",
            "El texto alude a su aspecto (las varices) y la desprecia por \"trola\". La respuesta final es \"mujer, aspecto\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Ginés González García: \"Le tengo mucho miedo al verano, el riesgo va a seguir\"\n",
            "texto: A este viejo le quedan 2 neuronas 1 para comer 2 para cagar\n",
            "[/INST]\n",
            "El texto alude a su edad, aduciendo que no tiene capacidades mentales acordes. La respuesta final es \"aspecto\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Otro ataque de furia contra un colectivero: una mujer trans le pateó la unidad y le tiró un ladrillazo\n",
            "texto: Un tipo operado. Con la fuerza de un hombre y no la de una mujer\n",
            "[/INST]\n",
            "El texto alude a que la mujer trans es un hombre. La respuesta final es \"lgbti\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Elisa Carrió denunció que el Gobierno usa la pandemia para \"establecer un estado de sitio\"\n",
            "texto: Gorda psiquiátrica\n",
            "[/INST]\n",
            "El texto alude a su aspecto (gorda) y la acusa de tener problemas psiquiátricos. La respuesta final es \"aspecto, discapacidad\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: 'País de maricas': ¿Por qué Jair Bolsonaro vuelve a atacar a los homosexuales en Brasil?\n",
            "texto: El discurso de bolsonaro donde dice \"maricas\" es brillante, sólo eso basta para meresca ser el presidente de Sudamérica. Clarín es una cueva de zurdos y progresistas que se pintan los labios punto. Clarín suavecito, te pasas de marica!\n",
            "[/INST]\n",
            "El texto alude a la homosexualidad como algo negativo, a la vez que acusa de ser \"zurdos y progresistas\" a quienes no están de acuerdo con el discurso de Bolsonaro. La respuesta final es \"lgbti, política\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Coronavirus: las terribles imágenes del mercado donde se originó la pandemia\n",
            "texto: Como se llama la obra? Estigmaticemos a los chinos\n",
            "[/INST]\n",
            "El texto critica el titular del artículo por \"estigmatizar a los chinos\". Es un comentario irónico. La respuesta final es \"nada\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: Los dos presos heridos de bala en el motín de Devoto tienen Covid-19 y uno quedó hemipléjico\n",
            "texto: justicia divina!\n",
            "[/INST]\n",
            "El texto alude a que los presos merecen ser baleados. La respuesta final es \"criminal\".\n",
            "</s> \n",
            "[INST] \n",
            "contexto: ¿Se puede ser feminista y llorar a Diego Maradona? url url\n",
            "texto: Ustedes son una mierda\n",
            "[/INST]\n",
            "El texto no hace referencia a ninguna de las características protegidas. La respuesta final es \"nada\".\n",
            "\n",
            "Nota: El texto original no parece estar relacionado con el contexto proporcionado.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(outs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b897d932a7a94cbb858f80871bdf75cc",
            "c5d5a8c07d7043e491bfdd69a024c79a",
            "c763d3456ae94c9a848af75aa1d20b53",
            "bf78a83ab76a430795214bdd67499fe0",
            "ca6c7557ab81487a8a291bbc85ac511b",
            "3cbe343b7f5c4ba9bd8fcede242c0aaa",
            "73841c98bcb5412ca985fe5b6350c00b",
            "d7340542531a4511939652ed44cfc9db",
            "52a14f0ed5fa4648b9223f12b899f1fc",
            "ec589bfc457e486a9f05e91994e87480",
            "5291dcf67b8c4b60bce58b085461a8bc"
          ]
        },
        "id": "A8SJSJsZBz-9",
        "outputId": "b7a3c043-eb5d-44c3-8bb0-29ce2ae28dc0"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "for ids, inputs in tqdm(dataloader):\n",
        "    output = model.generate(**inputs, max_new_tokens=150)\n",
        "\n",
        "    for k, id in enumerate(ids):\n",
        "        output_text = tokenizer.decode(output[k], skip_special_tokens=True)\n",
        "\n",
        "        #with open(path+\"/{}.txt\".format(id), \"w\") as f:\n",
        "        #    f.write(output_text)\n",
        "\n",
        "    #for _ in range(4):\n",
        "    #    print(\"=\"*80)\n",
        "    #print(f\"contexto: {contexto}\")\n",
        "    #print(f\"texto: {texto}\")\n",
        "    #print(output_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWWjWh6UOAw8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMaKfCdgHkmQ8TrGtDRLego",
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00372a68d1844733927384a1a278e29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a164cb3c8c64d5cbacd26b44a6cd528",
            "placeholder": "​",
            "style": "IPY_MODEL_a08fdf7223c34a02924fcdda3c0ef4b5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "04d06ca709604f5b893807c12de47770": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbe343b7f5c4ba9bd8fcede242c0aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5291dcf67b8c4b60bce58b085461a8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a14f0ed5fa4648b9223f12b899f1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a164cb3c8c64d5cbacd26b44a6cd528": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73841c98bcb5412ca985fe5b6350c00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a08fdf7223c34a02924fcdda3c0ef4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6fa2b0319334f939f79cf6b19d9ea9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b897d932a7a94cbb858f80871bdf75cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5d5a8c07d7043e491bfdd69a024c79a",
              "IPY_MODEL_c763d3456ae94c9a848af75aa1d20b53",
              "IPY_MODEL_bf78a83ab76a430795214bdd67499fe0"
            ],
            "layout": "IPY_MODEL_ca6c7557ab81487a8a291bbc85ac511b"
          }
        },
        "bf78a83ab76a430795214bdd67499fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec589bfc457e486a9f05e91994e87480",
            "placeholder": "​",
            "style": "IPY_MODEL_5291dcf67b8c4b60bce58b085461a8bc",
            "value": " 76/1418 [59:59&lt;18:19:43, 49.17s/it]"
          }
        },
        "c5d5a8c07d7043e491bfdd69a024c79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cbe343b7f5c4ba9bd8fcede242c0aaa",
            "placeholder": "​",
            "style": "IPY_MODEL_73841c98bcb5412ca985fe5b6350c00b",
            "value": "  5%"
          }
        },
        "c763d3456ae94c9a848af75aa1d20b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7340542531a4511939652ed44cfc9db",
            "max": 1418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52a14f0ed5fa4648b9223f12b899f1fc",
            "value": 76
          }
        },
        "ca6c7557ab81487a8a291bbc85ac511b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcf77dcbba64f4d8daf6416ed6a6336": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7340542531a4511939652ed44cfc9db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd73707fecb45abb0d13b4e6a9ec7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec589bfc457e486a9f05e91994e87480": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23addb7ed2c43a0a76763bf5fd17386": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbcf77dcbba64f4d8daf6416ed6a6336",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb363bd9978549618e8936fdcaac1eaf",
            "value": 19
          }
        },
        "f94daf71a1164b1e8eacada0b459f259": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd73707fecb45abb0d13b4e6a9ec7fb",
            "placeholder": "​",
            "style": "IPY_MODEL_a6fa2b0319334f939f79cf6b19d9ea9e",
            "value": " 19/19 [06:44&lt;00:00, 19.69s/it]"
          }
        },
        "fb363bd9978549618e8936fdcaac1eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe90396704a94c6ba9d1dab55cdc34fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00372a68d1844733927384a1a278e29a",
              "IPY_MODEL_f23addb7ed2c43a0a76763bf5fd17386",
              "IPY_MODEL_f94daf71a1164b1e8eacada0b459f259"
            ],
            "layout": "IPY_MODEL_04d06ca709604f5b893807c12de47770"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
